{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9b815f-8e0d-4f3a-9730-35a729254216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (2.2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d658d74e-f8e4-4909-b66a-499ce2046e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading, Writing and Displaying Images\n",
    "import cv2\n",
    "\n",
    "image_unchanged = cv2.imread('cloth.jpg', cv2.IMREAD_UNCHANGED)\n",
    "image_grayscale = cv2.imread('cloth.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "image_color = cv2.imread('cloth.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "cv2.imshow('Grayscale Image', image_grayscale)\n",
    "cv2.imshow('Grayscale Image', image_unchanged)\n",
    "cv2.imshow('Grayscale Image', image_color)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08fc7c2-fc56-421f-9eee-9dcbee9afda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames for second:  25.0 FPS\n",
      "Frame count:  319.0\n"
     ]
    }
   ],
   "source": [
    "# Reading, Writing and Displaying Videos\n",
    "# Videos are nothing but the series of images or frames\n",
    "\n",
    "import cv2\n",
    "\n",
    "video_cap = cv2.VideoCapture('test-video.mp4')\n",
    "\n",
    "if video_cap.isOpened() == False:\n",
    "    print(\"Error reading the video file\")\n",
    "\n",
    "else:\n",
    "    fps = video_cap.get(5)\n",
    "    print(\"Frames for second: \", fps, 'FPS')\n",
    "\n",
    "    frame_count = video_cap.get(7)\n",
    "    print(\"Frame count: \", frame_count)\n",
    "\n",
    "    while video_cap.isOpened():\n",
    "        ret, frame = video_cap.read()\n",
    "        if ret == True:\n",
    "            cv2.imshow('Frame', frame)\n",
    "            key = cv2.waitKey(20)\n",
    "\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c89bc09-2f98-4615-b30a-7f07f60e8b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second: FPS ->  0.0\n",
      "Frames count:  -1.0\n"
     ]
    }
   ],
   "source": [
    "## Reading data from camera\n",
    "\n",
    "import cv2\n",
    "\n",
    "cam_cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "\n",
    "if cam_cap.isOpened() == False:\n",
    "    print(\"Error Openeing Camera\")\n",
    "else:\n",
    "    fps = cam_cap.get(5)\n",
    "    print(\"Frames per second: FPS -> \", fps)\n",
    "\n",
    "    fc = cam_cap.get(7)\n",
    "    print(\"Frames count: \", fc)\n",
    "\n",
    "    while cam_cap.isOpened():\n",
    "        ret, frame = cam_cap.read()\n",
    "\n",
    "        if ret == True:\n",
    "            cv2.imshow('Camera', frame)\n",
    "            k = cv2.waitKey(20)\n",
    "\n",
    "            if k == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1634618a-205f-4b4f-b58c-774d7ee0fc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (1125, 750)\n",
      "(600, 600)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('cloth.jpg', 0)\n",
    "\n",
    "shape = img.shape\n",
    "\n",
    "print('Shape', shape)\n",
    "\n",
    "wid = 600\n",
    "hei = 600\n",
    "poi = (wid, hei)\n",
    "\n",
    "re_img = cv2.resize(img, poi, interpolation = cv2.INTER_LINEAR)\n",
    "cv2.imshow('Resized Image', re_img)\n",
    "\n",
    "print(re_img.shape)\n",
    "\n",
    "\n",
    "#cv2.imshow('Image', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1adf71b3-fe2c-4454-a23f-991a7c023994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open-Cv\n"
     ]
    }
   ],
   "source": [
    "print(\"Open-Cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e203db9-1e78-4bb4-be70-b56fdba164a7",
   "metadata": {},
   "source": [
    "# Below Code Working Perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77d367f2-b755-432a-a99a-6421e73a7624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_upper_body(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error: Could not read image\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Load OpenCV's face detector\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        print(\"No face detected\")\n",
    "        return None\n",
    "    \n",
    "    # Get the first face (assuming one person in the image)\n",
    "    (x, y, w, h) = faces[0]\n",
    "    \n",
    "    # Estimate neck position (below the face)\n",
    "    neck_y = y + h\n",
    "    \n",
    "    # Estimate shoulder width (approximately 1.5x face width)\n",
    "    shoulder_width = int(w * 1.5)\n",
    "    left_shoulder_x = x - int((shoulder_width - w) / 2)\n",
    "    right_shoulder_x = left_shoulder_x + shoulder_width\n",
    "    \n",
    "    # Ensure shoulder coordinates are within image bounds\n",
    "    left_shoulder_x = max(0, left_shoulder_x)\n",
    "    right_shoulder_x = min(image.shape[1] - 1, right_shoulder_x)\n",
    "    \n",
    "    # Estimate hips position (approximately 2x face height below face)\n",
    "    hips_y = neck_y + int(h * 2)\n",
    "    hips_y = min(hips_y, image.shape[0] - 1)  # Don't exceed image height\n",
    "    \n",
    "    # Return the coordinates of the upper body rectangle\n",
    "    upper_body_rect = (\n",
    "        left_shoulder_x,  # x1\n",
    "        neck_y,           # y1\n",
    "        right_shoulder_x, # x2\n",
    "        hips_y            # y2\n",
    "    )\n",
    "    \n",
    "    return image, upper_body_rect\n",
    "\n",
    "def process_cloth_image(cloth_path, target_width, target_height):\n",
    "    # Load the cloth image with alpha channel if available\n",
    "    cloth = cv2.imread(cloth_path, cv2.IMREAD_UNCHANGED)\n",
    "    if cloth is None:\n",
    "        print(\"Error: Could not read cloth image\")\n",
    "        return None\n",
    "    \n",
    "    # If image has alpha channel, use it as mask\n",
    "    if cloth.shape[2] == 4:\n",
    "        cloth_rgb = cloth[:, :, :3]\n",
    "        mask = cloth[:, :, 3]\n",
    "        \n",
    "        # Threshold the mask to get binary mask\n",
    "        _, mask = cv2.threshold(mask, 10, 255, cv2.THRESH_BINARY)\n",
    "    else:\n",
    "        # If no alpha channel, create mask using color thresholding\n",
    "        cloth_rgb = cloth.copy()\n",
    "        \n",
    "        # Convert to HSV color space for better color segmentation\n",
    "        hsv = cv2.cvtColor(cloth_rgb, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Define range for background color (assuming white background)\n",
    "        lower_white = np.array([0, 0, 200])\n",
    "        upper_white = np.array([180, 30, 255])\n",
    "        \n",
    "        # Create mask for background\n",
    "        mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "        mask = cv2.bitwise_not(mask)  # Invert to get foreground\n",
    "        \n",
    "        # Clean up mask with morphological operations\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        print(\"No contours found in cloth image\")\n",
    "        return None\n",
    "    \n",
    "    # Get the largest contour (assuming this is the clothing item)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Get bounding rectangle of the largest contour\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    \n",
    "    # Crop the cloth image to the bounding rectangle\n",
    "    cloth_cropped = cloth_rgb[y:y+h, x:x+w]\n",
    "    mask_cropped = mask[y:y+h, x:x+w]\n",
    "    \n",
    "    # Resize to target dimensions while maintaining aspect ratio\n",
    "    # First calculate the scaling factor\n",
    "    scale_w = target_width / w\n",
    "    scale_h = target_height / h\n",
    "    scale = min(scale_w, scale_h)\n",
    "    \n",
    "    new_w = int(w * scale)\n",
    "    new_h = int(h * scale)\n",
    "    \n",
    "    cloth_resized = cv2.resize(cloth_cropped, (new_w, new_h))\n",
    "    mask_resized = cv2.resize(mask_cropped, (new_w, new_h))\n",
    "    \n",
    "    # Create canvas of target size with black background\n",
    "    cloth_final = np.zeros((target_height, target_width, 3), dtype=np.uint8)\n",
    "    mask_final = np.zeros((target_height, target_width), dtype=np.uint8)\n",
    "    \n",
    "    # Center the resized cloth on the canvas\n",
    "    x_offset = (target_width - new_w) // 2\n",
    "    y_offset = (target_height - new_h) // 2\n",
    "    \n",
    "    cloth_final[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = cloth_resized\n",
    "    mask_final[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = mask_resized\n",
    "    \n",
    "    return cloth_final, mask_final\n",
    "\n",
    "def overlay_cloth(person_image, upper_body_rect, cloth_image, cloth_mask):\n",
    "    # Extract upper body coordinates\n",
    "    x1, y1, x2, y2 = upper_body_rect\n",
    "    upper_body_width = x2 - x1\n",
    "    upper_body_height = y2 - y1\n",
    "    \n",
    "    # Convert mask to 3 channels and normalize to [0,1]\n",
    "    mask = cv2.merge([cloth_mask, cloth_mask, cloth_mask]) / 255.0\n",
    "    \n",
    "    # Get the region of interest from the original image\n",
    "    roi = person_image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Make sure cloth and mask match ROI dimensions\n",
    "    if cloth_image.shape[0] != roi.shape[0] or cloth_image.shape[1] != roi.shape[1]:\n",
    "        cloth_image = cv2.resize(cloth_image, (roi.shape[1], roi.shape[0]))\n",
    "        mask = cv2.resize(mask, (roi.shape[1], roi.shape[0]))\n",
    "    \n",
    "    # Blend the cloth with the ROI using the mask\n",
    "    blended_roi = (roi * (1 - mask) + cloth_image * mask).astype(np.uint8)\n",
    "    \n",
    "    # Put the blended ROI back into the original image\n",
    "    result = person_image.copy()\n",
    "    result[y1:y2, x1:x2] = blended_roi\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # Paths to images\n",
    "    person_image_path = \"user.jpg\"  # Replace with your image path\n",
    "    cloth_image_path = \"cloth_rbg.png\"    # Replace with your cloth image path\n",
    "    \n",
    "    # Step 1: Detect upper body (neck to hips)\n",
    "    result = detect_upper_body(person_image_path)\n",
    "    if result is None:\n",
    "        return\n",
    "    \n",
    "    person_image, upper_body_rect = result\n",
    "    \n",
    "    # Draw rectangle for debugging\n",
    "    debug_image = person_image.copy()\n",
    "    cv2.rectangle(debug_image, (upper_body_rect[0], upper_body_rect[1]), \n",
    "                 (upper_body_rect[2], upper_body_rect[3]), (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Upper Body Detection\", debug_image)\n",
    "    \n",
    "    # Step 2: Process cloth image\n",
    "    upper_body_width = upper_body_rect[2] - upper_body_rect[0]\n",
    "    upper_body_height = upper_body_rect[3] - upper_body_rect[1]\n",
    "    cloth_result = process_cloth_image(cloth_image_path, upper_body_width, upper_body_height)\n",
    "    if cloth_result is None:\n",
    "        return\n",
    "    \n",
    "    cloth_image, cloth_mask = cloth_result\n",
    "    \n",
    "    # Step 3: Overlay cloth on person\n",
    "    result = overlay_cloth(person_image, upper_body_rect, cloth_image, cloth_mask)\n",
    "    \n",
    "    # Display results\n",
    "    cv2.imshow(\"Original\", person_image)\n",
    "    cv2.imshow(\"Cloth Mask\", cloth_mask)\n",
    "    cv2.imshow(\"Virtual Try-On\", result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Save result\n",
    "    cv2.imwrite(\"virtual_try_on_result.jpg\", result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae0e2f7-d50d-4d66-b15f-a0836c1fb75e",
   "metadata": {},
   "source": [
    "## New Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a37af4e9-4eeb-4552-84a3-e906e9bb16e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper body not detected - using face-based estimation\n",
      "Upper body dimensions: 254x381\n",
      "Resized dimensions: 324x358 (scale: 1.20)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_upper_body(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error: Could not read image\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Load OpenCV's face and upper body detectors\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    upper_body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_upperbody.xml')\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray, \n",
    "        scaleFactor=1.1, \n",
    "        minNeighbors=5, \n",
    "        minSize=(100, 100)  # Larger minimum size for better detection\n",
    "    )\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        print(\"No face detected - trying upper body detection directly\")\n",
    "        # If no face detected, try detecting upper body directly\n",
    "        upper_bodies = upper_body_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.05,\n",
    "            minNeighbors=5,\n",
    "            minSize=(100, 100)\n",
    "        )\n",
    "        if len(upper_bodies) == 0:\n",
    "            print(\"No upper body detected\")\n",
    "            return None\n",
    "        # Use the first upper body detection\n",
    "        (x, y, w, h) = upper_bodies[0]\n",
    "        # Adjust the rectangle to cover from neck to hips\n",
    "        upper_body_rect = (\n",
    "            x - int(w * 0.2),  # Expand width by 20%\n",
    "            y + int(h * 0.3),  # Start slightly above detected upper body\n",
    "            x + w + int(w * 0.2),  # Expand width by 20%\n",
    "            y + int(h * 1.2)  # Extend downward\n",
    "        )\n",
    "    else:\n",
    "        # Get the first face (assuming one person in the image)\n",
    "        (x, y, w, h) = faces[0]\n",
    "        \n",
    "        # Detect upper body below the face\n",
    "        upper_bodies = upper_body_cascade.detectMultiScale(\n",
    "            gray[y+h//2:],  # Search below face\n",
    "            scaleFactor=1.05,\n",
    "            minNeighbors=5,\n",
    "            minSize=(w, h)  # At least as wide as the face\n",
    "        )\n",
    "        \n",
    "        if len(upper_bodies) > 0:\n",
    "            # Use the first upper body detection\n",
    "            (ub_x, ub_y, ub_w, ub_h) = upper_bodies[0]\n",
    "            # Adjust coordinates relative to full image\n",
    "            ub_y += y + h//2\n",
    "            \n",
    "            # Calculate upper body rectangle\n",
    "            upper_body_rect = (\n",
    "                ub_x - int(ub_w * 0.1),  # Expand width by 10%\n",
    "                ub_y - int(ub_h * 0.2),  # Start slightly above detected upper body\n",
    "                ub_x + ub_w + int(ub_w * 0.1),  # Expand width by 10%\n",
    "                ub_y + int(ub_h * 1.1)  # Extend downward\n",
    "            )\n",
    "        else:\n",
    "            # Fallback to face-based estimation if upper body not detected\n",
    "            print(\"Upper body not detected - using face-based estimation\")\n",
    "            # Estimate neck position (below the face)\n",
    "            neck_y = y + h\n",
    "            \n",
    "            # Estimate shoulder width (approximately 2x face width)\n",
    "            shoulder_width = int(w * 2)\n",
    "            left_shoulder_x = x - int((shoulder_width - w) / 2)\n",
    "            right_shoulder_x = left_shoulder_x + shoulder_width\n",
    "            \n",
    "            # Estimate hips position (approximately 3x face height below face)\n",
    "            hips_y = neck_y + int(h * 3)\n",
    "            \n",
    "            upper_body_rect = (\n",
    "                left_shoulder_x,\n",
    "                neck_y,\n",
    "                right_shoulder_x,\n",
    "                hips_y\n",
    "            )\n",
    "    \n",
    "    # Ensure coordinates are within image bounds\n",
    "    upper_body_rect = (\n",
    "        max(0, upper_body_rect[0]),\n",
    "        max(0, upper_body_rect[1]),\n",
    "        min(image.shape[1] - 1, upper_body_rect[2]),\n",
    "        min(image.shape[0] - 1, upper_body_rect[3])\n",
    "    )\n",
    "    \n",
    "    # Verify the rectangle has valid dimensions\n",
    "    if (upper_body_rect[2] <= upper_body_rect[0]) or (upper_body_rect[3] <= upper_body_rect[1]):\n",
    "        print(\"Invalid upper body dimensions\")\n",
    "        return None\n",
    "    \n",
    "    return image, upper_body_rect\n",
    "\n",
    "def process_cloth_image(cloth_path, target_width, target_height):\n",
    "    # Load the cloth image with alpha channel if available\n",
    "    cloth = cv2.imread(cloth_path, cv2.IMREAD_UNCHANGED)\n",
    "    if cloth is None:\n",
    "        print(\"Error: Could not read cloth image\")\n",
    "        return None\n",
    "    \n",
    "    # If image has alpha channel, use it as mask\n",
    "    if cloth.shape[2] == 4:\n",
    "        cloth_rgb = cloth[:, :, :3]\n",
    "        mask = cloth[:, :, 3]\n",
    "    else:\n",
    "        # If no alpha channel, use background removal\n",
    "        cloth_rgb = cloth.copy()\n",
    "        \n",
    "        # Create a mask using color thresholding in LAB color space\n",
    "        lab = cv2.cvtColor(cloth_rgb, cv2.COLOR_BGR2LAB)\n",
    "        \n",
    "        # Threshold on lightness channel (better for both light and dark backgrounds)\n",
    "        l_channel = lab[:,:,0]\n",
    "        \n",
    "        # Adaptive thresholding works better than global threshold\n",
    "        mask = cv2.adaptiveThreshold(\n",
    "            l_channel, 255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV, 51, 10\n",
    "        )\n",
    "        \n",
    "        # Clean up mask with morphological operations\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "        \n",
    "        # Find largest contour\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if len(contours) > 0:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            mask = np.zeros_like(mask)\n",
    "            cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "    \n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if len(contours) == 0:\n",
    "        print(\"No contours found in cloth image\")\n",
    "        return None\n",
    "    \n",
    "    # Get the largest contour (assuming this is the clothing item)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Get bounding rectangle of the largest contour\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    \n",
    "    # Crop the cloth image to the bounding rectangle\n",
    "    cloth_cropped = cloth_rgb[y:y+h, x:x+w]\n",
    "    mask_cropped = mask[y:y+h, x:x+w]\n",
    "    \n",
    "    # Calculate aspect ratios\n",
    "    cloth_aspect = w / h\n",
    "    target_aspect = target_width / target_height\n",
    "\n",
    "        # Calculate aspect ratios\n",
    "    cloth_aspect = w / h\n",
    "    target_aspect = target_width / target_height\n",
    "    \n",
    "    # ==== KEY FIX: Add bounds checking ====\n",
    "    scale_factor = 1.2  # Start with this, adjust as needed\n",
    "    \n",
    "    # Calculate maximum possible scale that fits within target\n",
    "    max_scale_width = target_width / w\n",
    "    max_scale_height = target_height / h\n",
    "    max_possible_scale = min(max_scale_width, max_scale_height)\n",
    "    \n",
    "    # Apply scaling (ensure we don't exceed bounds)\n",
    "    effective_scale = min(scale_factor, max_possible_scale * 1.5)  # 5% margin\n",
    "    \n",
    "    if cloth_aspect > target_aspect:\n",
    "        new_w = int(w * effective_scale)\n",
    "        new_h = int(h * effective_scale)\n",
    "    else:\n",
    "        new_h = int(h * effective_scale)\n",
    "        new_w = int(w * effective_scale)\n",
    "    \n",
    "    print(f\"Resized dimensions: {new_w}x{new_h} (scale: {effective_scale:.2f})\")\n",
    "    \n",
    "    # Resize the images\n",
    "    cloth_resized = cv2.resize(cloth_cropped, (new_w, new_h))\n",
    "    mask_resized = cv2.resize(mask_cropped, (new_w, new_h))\n",
    "    \n",
    "    # Create canvas\n",
    "    cloth_final = np.zeros((target_height, target_width, 3), dtype=np.uint8)\n",
    "    mask_final = np.zeros((target_height, target_width), dtype=np.uint8)\n",
    "    \n",
    "    # Calculate centered position with bounds checking\n",
    "    x_offset = max(0, (target_width - new_w) // 2 - 50)\n",
    "    y_offset = max(0, (target_height - new_h) // 2 - 10)  # Your upward shift\n",
    "    \n",
    "    # Ensure we don't exceed array bounds\n",
    "    y_end = min(y_offset + new_h, target_height)\n",
    "    x_end = min(x_offset + new_w, target_width)\n",
    "    \n",
    "    # Adjust if needed\n",
    "    if y_end - y_offset < new_h:\n",
    "        new_h = y_end - y_offset\n",
    "    if x_end - x_offset < new_w:\n",
    "        new_w = x_end - x_offset\n",
    "    \n",
    "    # Final assignment with safe dimensions\n",
    "    cloth_final[y_offset:y_end, x_offset:x_end] = cloth_resized[:new_h, :new_w]\n",
    "    mask_final[y_offset:y_end, x_offset:x_end] = mask_resized[:new_h, :new_w]\n",
    "    \n",
    "    return cloth_final, mask_final\n",
    "\n",
    "    '''# ==== KEY CHANGE: Add scaling factor here ====\n",
    "    scale_factor = 1.2  # Increase this to make the cloth bigger (e.g., 1.2 = 20% larger)\n",
    "    \n",
    "    # Determine resize dimensions\n",
    "    if cloth_aspect > target_aspect:\n",
    "        # Cloth is wider than target - fit to width\n",
    "        print(\"Cloth is wider than target\")\n",
    "        new_w = int(target_width * scale_factor)  # Apply scaling\n",
    "        new_h = int(new_w / cloth_aspect)  # Maintain aspect ratio\n",
    "\n",
    "        print(\"new height: \", new_h)\n",
    "        print(\"new width: \", new_w)\n",
    "    else:\n",
    "        # Cloth is taller than target - fit to height\n",
    "        # Cloth is taller than target - fit to height\n",
    "        print(\"cloth is not wider than target\")\n",
    "        new_h = int(target_height * scale_factor)  # Apply scaling\n",
    "        new_w = int(new_h * cloth_aspect)  # Maintain aspect ratio\n",
    "\n",
    "        print(\"new height: \", new_h)\n",
    "        print(\"new width: \", new_w)\n",
    "    \n",
    "    # Resize maintaining aspect ratio\n",
    "    cloth_resized = cv2.resize(cloth_cropped, (new_w, new_h))\n",
    "    mask_resized = cv2.resize(mask_cropped, (new_w, new_h))\n",
    "    \n",
    "    # Create canvas of target size\n",
    "    cloth_final = np.zeros((target_height, target_width, 3), dtype=np.uint8)\n",
    "    mask_final = np.zeros((target_height, target_width), dtype=np.uint8)\n",
    "    \n",
    "    # Center the resized cloth on the canvas\n",
    "    x_offset = (target_width - new_w) // 2\n",
    "    y_offset = (target_height - new_h) // 2 - 25  #Shift up\n",
    "    \n",
    "    cloth_final[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = cloth_resized\n",
    "    mask_final[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = mask_resized\n",
    "    \n",
    "    return cloth_final, mask_final'''\n",
    "\n",
    "def overlay_cloth(person_image, upper_body_rect, cloth_image, cloth_mask):\n",
    "    # Extract upper body coordinates\n",
    "    x1, y1, x2, y2 = upper_body_rect\n",
    "    upper_body_width = x2 - x1\n",
    "    upper_body_height = y2 - y1\n",
    "    \n",
    "    # Convert mask to 3 channels and normalize to [0,1]\n",
    "    mask = cv2.merge([cloth_mask, cloth_mask, cloth_mask]) / 255.0\n",
    "    \n",
    "    # Get the region of interest from the original image\n",
    "    roi = person_image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Resize cloth and mask to exactly match ROI dimensions\n",
    "    cloth_resized = cv2.resize(cloth_image, (roi.shape[1], roi.shape[0]))\n",
    "    mask_resized = cv2.resize(mask, (roi.shape[1], roi.shape[0]))\n",
    "    \n",
    "    # Blend the cloth with the ROI using the mask\n",
    "    blended_roi = (roi * (1 - mask_resized) + cloth_resized * mask_resized).astype(np.uint8)\n",
    "    \n",
    "    # Put the blended ROI back into the original image\n",
    "    result = person_image.copy()\n",
    "    result[y1:y2, x1:x2] = blended_roi\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    # Paths to images\n",
    "    person_image_path = \"user.jpg\"  # Replace with your image path\n",
    "    cloth_image_path = \"cloth_rbg.png\"    # Replace with your cloth image path\n",
    "    \n",
    "    # Step 1: Detect upper body with improved sizing\n",
    "    result = detect_upper_body(person_image_path)\n",
    "    if result is None:\n",
    "        return\n",
    "    \n",
    "    person_image, upper_body_rect = result\n",
    "    \n",
    "    # Draw rectangle for debugging\n",
    "    debug_image = person_image.copy()\n",
    "    cv2.rectangle(debug_image, \n",
    "                 (upper_body_rect[0], upper_body_rect[1]), \n",
    "                 (upper_body_rect[2], upper_body_rect[3]), \n",
    "                 (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Upper Body Detection\", debug_image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    # Step 2: Process cloth image with improved sizing\n",
    "    upper_body_width = upper_body_rect[2] - upper_body_rect[0]\n",
    "    upper_body_height = upper_body_rect[3] - upper_body_rect[1]\n",
    "    \n",
    "    print(f\"Upper body dimensions: {upper_body_width}x{upper_body_height}\")\n",
    "    \n",
    "    cloth_result = process_cloth_image(cloth_image_path, upper_body_width, upper_body_height)\n",
    "    if cloth_result is None:\n",
    "        return\n",
    "    \n",
    "    cloth_image, cloth_mask = cloth_result\n",
    "    \n",
    "    # Show processed cloth for debugging\n",
    "    cv2.imshow(\"Processed Cloth\", cloth_image)\n",
    "    cv2.imshow(\"Cloth Mask\", cloth_mask)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    # Step 3: Overlay cloth on person with proper fitting\n",
    "    result = overlay_cloth(person_image, upper_body_rect, cloth_image, cloth_mask)\n",
    "    \n",
    "    # Display final result\n",
    "    cv2.imshow(\"Original\", person_image)\n",
    "    cv2.imshow(\"Virtual Try-On\", result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Save result\n",
    "    cv2.imwrite(\"virtual_try_on_result.jpg\", result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbf5a55-0626-4b29-aeaf-b4f3050d9152",
   "metadata": {},
   "source": [
    "## Working Perfect: Verified / Need some modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "08ff2fbf-6aab-423d-a53b-af105b6f839c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper body not detected - using face-based estimation\n",
      "Upper body dimensions: 317x381\n",
      "Cloth dimensions: 313x347 (Scale: 1.16)\n",
      "Final position - X: 0, Y: 17\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_upper_body(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error: Could not read image\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Load OpenCV's face and upper body detectors\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    upper_body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_upperbody.xml')\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray, \n",
    "        scaleFactor=1.1, \n",
    "        minNeighbors=5, \n",
    "        minSize=(100, 100)\n",
    "    )\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        print(\"No face detected - trying upper body detection directly\")\n",
    "        # If no face detected, try detecting upper body directly\n",
    "        upper_bodies = upper_body_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.05,\n",
    "            minNeighbors=5,\n",
    "            minSize=(100, 100)\n",
    "        )\n",
    "        if len(upper_bodies) == 0:\n",
    "            print(\"No upper body detected\")\n",
    "            return None\n",
    "        # Use the first upper body detection with expanded width\n",
    "        (x, y, w, h) = upper_bodies[0]\n",
    "        # Adjust the rectangle to cover from neck to hips with more width expansion\n",
    "        width_expansion = 0.4  # Increased from 0.2 to 0.4 (40% expansion on each side)\n",
    "        upper_body_rect = (\n",
    "            x - int(w * width_expansion),  # Expand width left\n",
    "            y + int(h * 0.3),             # Start slightly above detected upper body\n",
    "            x + w + int(w * width_expansion),  # Expand width right\n",
    "            y + int(h * 1.2)              # Extend downward\n",
    "        )\n",
    "    else:\n",
    "        # Get the first face (assuming one person in the image)\n",
    "        (x, y, w, h) = faces[0]\n",
    "        \n",
    "        # Detect upper body below the face\n",
    "        upper_bodies = upper_body_cascade.detectMultiScale(\n",
    "            gray[y+h//2:],  # Search below face\n",
    "            scaleFactor=1.05,\n",
    "            minNeighbors=5,\n",
    "            minSize=(w, h))\n",
    "        \n",
    "        if len(upper_bodies) > 0:\n",
    "            # Use the first upper body detection with expanded width\n",
    "            (ub_x, ub_y, ub_w, ub_h) = upper_bodies[0]\n",
    "            # Adjust coordinates relative to full image\n",
    "            ub_y += y + h//2\n",
    "            \n",
    "            width_expansion = 0.3  # Increased from 0.1 to 0.3 (30% expansion on each side)\n",
    "            # Calculate upper body rectangle\n",
    "            upper_body_rect = (\n",
    "                ub_x - int(ub_w * width_expansion),  # Expand width left\n",
    "                ub_y - int(ub_h * 0.2),             # Start slightly above detected upper body\n",
    "                ub_x + ub_w + int(ub_w * width_expansion),  # Expand width right\n",
    "                ub_y + int(ub_h * 1.1)              # Extend downward\n",
    "            )\n",
    "        else:\n",
    "            # Fallback to face-based estimation with expanded width\n",
    "            print(\"Upper body not detected - using face-based estimation\")\n",
    "            # Estimate neck position (below the face)\n",
    "            neck_y = y + h\n",
    "            \n",
    "            # Estimate shoulder width with more expansion\n",
    "            shoulder_expansion = 2.5  # Increased from 2.0 to 2.5\n",
    "            shoulder_width = int(w * shoulder_expansion)\n",
    "            left_shoulder_x = x - int((shoulder_width - w) / 2)\n",
    "            right_shoulder_x = left_shoulder_x + shoulder_width\n",
    "            \n",
    "            # Estimate hips position\n",
    "            hips_y = neck_y + int(h * 3)\n",
    "            \n",
    "            upper_body_rect = (\n",
    "                left_shoulder_x,\n",
    "                neck_y,\n",
    "                right_shoulder_x,\n",
    "                hips_y\n",
    "            )\n",
    "    \n",
    "    upper_body_rect = (\n",
    "        max(0, upper_body_rect[0]),\n",
    "        max(0, upper_body_rect[1]),\n",
    "        min(image.shape[1] - 1, upper_body_rect[2]),\n",
    "        min(image.shape[0] - 1, upper_body_rect[3])\n",
    "    )\n",
    "    \n",
    "    if (upper_body_rect[2] <= upper_body_rect[0]) or (upper_body_rect[3] <= upper_body_rect[1]):\n",
    "        print(\"Invalid upper body dimensions\")\n",
    "        return None\n",
    "    \n",
    "    return image, upper_body_rect\n",
    "\n",
    "def process_cloth_image(cloth_path, target_width, target_height):\n",
    "    # Load the cloth image with alpha channel if available\n",
    "    cloth = cv2.imread(cloth_path, cv2.IMREAD_UNCHANGED)\n",
    "    if cloth is None:\n",
    "        print(\"Error: Could not read cloth image\")\n",
    "        return None\n",
    "    \n",
    "    # Configuration parameters\n",
    "    LEFT_SHIFT_AMOUNT = 80  # Pixels to shift left (increase to move more left)\n",
    "    UPWARD_SHIFT = 0        # Pixels to shift up (negative to move down)\n",
    "    CLOTH_SCALE_FACTOR = 1.1 # Scale factor for cloth size\n",
    "    \n",
    "    # If image has alpha channel, use it as mask\n",
    "    if cloth.shape[2] == 4:\n",
    "        cloth_rgb = cloth[:, :, :3]\n",
    "        mask = cloth[:, :, 3]\n",
    "    else:\n",
    "        # If no alpha channel, use background removal\n",
    "        cloth_rgb = cloth.copy()\n",
    "        lab = cv2.cvtColor(cloth_rgb, cv2.COLOR_BGR2LAB)\n",
    "        l_channel = lab[:,:,0]\n",
    "        mask = cv2.adaptiveThreshold(\n",
    "            l_channel, 255,\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY_INV, 51, 10\n",
    "        )\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if len(contours) > 0:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            mask = np.zeros_like(mask)\n",
    "            cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "    \n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        print(\"No contours found in cloth image\")\n",
    "        return None\n",
    "    \n",
    "    # Get the largest contour (assuming this is the clothing item)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    \n",
    "    # Crop the cloth image to the bounding rectangle\n",
    "    cloth_cropped = cloth_rgb[y:y+h, x:x+w]\n",
    "    mask_cropped = mask[y:y+h, x:x+w]\n",
    "    \n",
    "    # Calculate aspect ratios with safety margins\n",
    "    cloth_aspect = w / h\n",
    "    target_aspect = (target_width * 0.9) / (target_height * 0.9)\n",
    "    \n",
    "    # Calculate maximum possible scale\n",
    "    max_scale_width = (target_width * 0.9) / w\n",
    "    max_scale_height = (target_height * 0.9) / h\n",
    "    effective_scale = min(max_scale_width, max_scale_height) * CLOTH_SCALE_FACTOR\n",
    "    \n",
    "    # Apply scaling\n",
    "    new_w = int(w * effective_scale)\n",
    "    new_h = int(h * effective_scale)\n",
    "    \n",
    "    print(f\"Cloth dimensions: {new_w}x{new_h} (Scale: {effective_scale:.2f})\")\n",
    "    \n",
    "    # Resize the images\n",
    "    cloth_resized = cv2.resize(cloth_cropped, (new_w, new_h))\n",
    "    mask_resized = cv2.resize(mask_cropped, (new_w, new_h))\n",
    "    \n",
    "    # Create canvas\n",
    "    cloth_final = np.zeros((target_height, target_width, 3), dtype=np.uint8)\n",
    "    mask_final = np.zeros((target_height, target_width), dtype=np.uint8)\n",
    "    \n",
    "    # Calculate position with leftward shift\n",
    "    x_offset = max(0, (target_width - new_w) // 2 - LEFT_SHIFT_AMOUNT)\n",
    "    y_offset = max(0, (target_height - new_h) // 2 + UPWARD_SHIFT)\n",
    "    \n",
    "    # Ensure we don't exceed array bounds\n",
    "    copy_width = min(new_w, target_width - x_offset)\n",
    "    copy_height = min(new_h, target_height - y_offset)\n",
    "    \n",
    "    # Place the cloth on the canvas\n",
    "    cloth_final[y_offset:y_offset+copy_height, x_offset:x_offset+copy_width] = \\\n",
    "        cloth_resized[:copy_height, :copy_width]\n",
    "    mask_final[y_offset:y_offset+copy_height, x_offset:x_offset+copy_width] = \\\n",
    "        mask_resized[:copy_height, :copy_width]\n",
    "    \n",
    "    print(f\"Final position - X: {x_offset}, Y: {y_offset}\")\n",
    "    return cloth_final, mask_final\n",
    "\n",
    "def overlay_cloth(person_image, upper_body_rect, cloth_image, cloth_mask):\n",
    "    x1, y1, x2, y2 = upper_body_rect\n",
    "    upper_body_width = x2 - x1\n",
    "    upper_body_height = y2 - y1\n",
    "    \n",
    "    mask = cv2.merge([cloth_mask, cloth_mask, cloth_mask]) / 255.0\n",
    "    roi = person_image[y1:y2, x1:x2]\n",
    "    \n",
    "    cloth_resized = cv2.resize(cloth_image, (roi.shape[1], roi.shape[0]))\n",
    "    mask_resized = cv2.resize(mask, (roi.shape[1], roi.shape[0]))\n",
    "    \n",
    "    blended_roi = (roi * (1 - mask_resized) + cloth_resized * mask_resized).astype(np.uint8)\n",
    "    \n",
    "    result = person_image.copy()\n",
    "    result[y1:y2, x1:x2] = blended_roi\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    person_image_path = \"user.jpg\"\n",
    "    cloth_image_path = \"cloth_rbg.png\"\n",
    "    \n",
    "    result = detect_upper_body(person_image_path)\n",
    "    if result is None:\n",
    "        return\n",
    "    \n",
    "    person_image, upper_body_rect = result\n",
    "    \n",
    "    debug_image = person_image.copy()\n",
    "    cv2.rectangle(debug_image, \n",
    "                 (upper_body_rect[0], upper_body_rect[1]), \n",
    "                 (upper_body_rect[2], upper_body_rect[3]), \n",
    "                 (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Upper Body Detection\", debug_image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    upper_body_width = upper_body_rect[2] - upper_body_rect[0]\n",
    "    upper_body_height = upper_body_rect[3] - upper_body_rect[1]\n",
    "    \n",
    "    print(f\"Upper body dimensions: {upper_body_width}x{upper_body_height}\")\n",
    "    \n",
    "    cloth_result = process_cloth_image(cloth_image_path, upper_body_width, upper_body_height)\n",
    "    if cloth_result is None:\n",
    "        return\n",
    "    \n",
    "    cloth_image, cloth_mask = cloth_result\n",
    "    \n",
    "    cv2.imshow(\"Processed Cloth\", cloth_image)\n",
    "    cv2.imshow(\"Cloth Mask\", cloth_mask)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    result = overlay_cloth(person_image, upper_body_rect, cloth_image, cloth_mask)\n",
    "    \n",
    "    cv2.imshow(\"Original\", person_image)\n",
    "    cv2.imshow(\"Virtual Try-On\", result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    cv2.imwrite(\"virtual_try_on_result.jpg\", result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27f0a3c4-438d-4e3d-8e8e-3e12e2a8ca12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper body not detected - using face-based estimation\n",
      "Upper body dimensions: 327x312\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def detect_upper_body(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error: Could not read image\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Load OpenCV's face and upper body detectors\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    upper_body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_upperbody.xml')\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray, \n",
    "        scaleFactor=1.1, \n",
    "        minNeighbors=5, \n",
    "        minSize=(100, 100)\n",
    "    )\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        print(\"No face detected - trying upper body detection directly\")\n",
    "        # If no face detected, try detecting upper body directly\n",
    "        upper_bodies = upper_body_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.05,\n",
    "            minNeighbors=5,\n",
    "            minSize=(100, 100)\n",
    "        )\n",
    "        if len(upper_bodies) == 0:\n",
    "            print(\"No upper body detected\")\n",
    "            return None\n",
    "        # Use the first upper body detection with expanded width\n",
    "        (x, y, w, h) = upper_bodies[0]\n",
    "        # Adjust the rectangle to cover from neck to hips with more width expansion\n",
    "        width_expansion = 0.6  # Increased to 50% expansion on each side\n",
    "        upper_body_rect = (\n",
    "            max(0, x - int(w * width_expansion)),  # Expand width left with bounds check\n",
    "            y + int(h * 0.3),                     # Start slightly above detected upper body\n",
    "            min(image.shape[1]-1, x + w + int(w * width_expansion)),  # Expand right with bounds\n",
    "            y + int(h * 1.2)                      # Extend downward\n",
    "        )\n",
    "    else:\n",
    "        # Get the first face (assuming one person in the image)\n",
    "        (x, y, w, h) = faces[0]\n",
    "        \n",
    "        # Detect upper body below the face\n",
    "        upper_bodies = upper_body_cascade.detectMultiScale(\n",
    "            gray[y+h//2:],  # Search below face\n",
    "            scaleFactor=1.05,\n",
    "            minNeighbors=5,\n",
    "            minSize=(w, h))\n",
    "        \n",
    "        if len(upper_bodies) > 0:\n",
    "            # Use the first upper body detection with expanded width\n",
    "            (ub_x, ub_y, ub_w, ub_h) = upper_bodies[0]\n",
    "            # Adjust coordinates relative to full image\n",
    "            ub_y += y + h//2\n",
    "            \n",
    "            width_expansion = 0.4  # Increased to 40% expansion on each side\n",
    "            # Calculate upper body rectangle\n",
    "            upper_body_rect = (\n",
    "                max(0, ub_x - int(ub_w * width_expansion)),  # Left expansion with bounds\n",
    "                ub_y - int(ub_h * 0.2),                     # Start slightly above\n",
    "                min(image.shape[1]-1, ub_x + ub_w + int(ub_w * width_expansion)),  # Right expansion\n",
    "                ub_y + int(ub_h * 1.1)                      # Extend downward\n",
    "            )\n",
    "        else:\n",
    "            # Fallback to face-based estimation with expanded width\n",
    "            print(\"Upper body not detected - using face-based estimation\")\n",
    "            # Estimate neck position (below the face)\n",
    "            neck_y = y + h\n",
    "            \n",
    "            # Estimate shoulder width with more expansion\n",
    "            shoulder_expansion = 3.15  # Increased from 2.5 to 3.0\n",
    "            shoulder_width = int(w * shoulder_expansion)\n",
    "            left_shoulder_x = max(0, x - int((shoulder_width - w) / 2))\n",
    "            right_shoulder_x = min(image.shape[1]-1, left_shoulder_x + shoulder_width)\n",
    "            \n",
    "            # Estimate hips position\n",
    "            hips_y = neck_y + int(h * 3)\n",
    "            \n",
    "            upper_body_rect = (\n",
    "                left_shoulder_x,\n",
    "                neck_y,\n",
    "                right_shoulder_x,\n",
    "                min(image.shape[0]-1, hips_y)  # Ensure within image bounds\n",
    "            )\n",
    "    \n",
    "    # Verify the rectangle has valid dimensions\n",
    "    if (upper_body_rect[2] <= upper_body_rect[0]) or (upper_body_rect[3] <= upper_body_rect[1]):\n",
    "        print(\"Invalid upper body dimensions\")\n",
    "        return None\n",
    "    \n",
    "    return image, upper_body_rect\n",
    "\n",
    "def process_cloth_image(cloth_path, target_width, target_height):\n",
    "    # Load the cloth image with alpha channel if available\n",
    "    cloth = cv2.imread(cloth_path, cv2.IMREAD_UNCHANGED)\n",
    "    if cloth is None:\n",
    "        print(\"Error: Could not read cloth image\")\n",
    "        return None\n",
    "    \n",
    "    # Configuration parameters\n",
    "    LEFT_SHIFT_RATIO = 0.18      # 18% of width shift (0.15-0.25 for best results)\n",
    "    RIGHT_SHIFT_AMOUNT = 40  # Pixels to shift right\n",
    "    UPWARD_SHIFT = 15            # Pixels to shift up (10-20 typical)\n",
    "    CLOTH_SCALE_FACTOR = 1.2     # Scale factor (1.0-1.3)\n",
    "    NECK_CUT_SENSITIVITY = 0.35  # Neck detection sensitivity (0.3-0.5)\n",
    "    MIN_NECK_WIDTH_RATIO = 0.4   # Minimum neck width ratio (0.3-0.5)\n",
    "\n",
    "    # Load image and create mask\n",
    "    if cloth.shape[2] == 4:\n",
    "        cloth_rgb = cloth[:, :, :3]\n",
    "        mask = cloth[:, :, 3]\n",
    "    else:\n",
    "        cloth_rgb = cloth.copy()\n",
    "        gray = cv2.cvtColor(cloth_rgb, cv2.COLOR_BGR2GRAY)\n",
    "        _, mask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    # Find main clothing contour\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        print(\"No contours found\")\n",
    "        return None\n",
    "    \n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    cloth_cropped = cloth_rgb[y:y+h, x:x+w]\n",
    "    mask_cropped = mask[y:y+h, x:x+w]\n",
    "\n",
    "   \n",
    "    # ====== SCALING AND POSITIONING ======\n",
    "    # Calculate scaling with 5% margin\n",
    "    max_scale_width = (target_width * 0.95) / w\n",
    "    max_scale_height = (target_height * 0.95) / h\n",
    "    effective_scale = min(max_scale_width, max_scale_height) * CLOTH_SCALE_FACTOR\n",
    "    new_w = int(w * effective_scale)\n",
    "    new_h = int(h * effective_scale)\n",
    "    \n",
    "    # Resize images\n",
    "    cloth_resized = cv2.resize(cloth_cropped, (new_w, new_h))\n",
    "    mask_resized = cv2.resize(mask_cropped, (new_w, new_h))\n",
    "    \n",
    "    # Calculate dynamic left shift\n",
    "    dynamic_left_shift = int(target_width * LEFT_SHIFT_RATIO)\n",
    "    x_offset = max(0, (target_width - new_w) // 2 - dynamic_left_shift + RIGHT_SHIFT_AMOUNT)\n",
    "    y_offset = max(0, (target_height - new_h) // 2 - UPWARD_SHIFT)\n",
    "    \n",
    "    # Create final images\n",
    "    cloth_final = np.zeros((target_height, target_width, 3), dtype=np.uint8)\n",
    "    mask_final = np.zeros((target_height, target_width), dtype=np.uint8)\n",
    "    \n",
    "    # Calculate safe copy regions\n",
    "    y_end = min(y_offset + new_h, target_height)\n",
    "    x_end = min(x_offset + new_w, target_width)\n",
    "    copy_height = y_end - y_offset\n",
    "    copy_width = x_end - x_offset\n",
    "    \n",
    "    # Apply to final images\n",
    "    cloth_final[y_offset:y_end, x_offset:x_end] = cloth_resized[:copy_height, :copy_width]\n",
    "    mask_final[y_offset:y_end, x_offset:x_end] = mask_resized[:copy_height, :copy_width]\n",
    "    \n",
    "    # Debug visualization\n",
    "    debug_img = cloth_final.copy()\n",
    "    cv2.rectangle(debug_img, (x_offset, y_offset), (x_end, y_end), (0,255,0), 2)\n",
    "    cv2.putText(debug_img, f\"X: {x_offset}\", (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "    cv2.imshow(\"Cloth Positioning\", debug_img)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    return cloth_final, mask_final\n",
    "\n",
    "def overlay_cloth(person_image, upper_body_rect, cloth_image, cloth_mask):\n",
    "    x1, y1, x2, y2 = upper_body_rect\n",
    "    upper_body_width = x2 - x1\n",
    "    upper_body_height = y2 - y1\n",
    "    \n",
    "    mask = cv2.merge([cloth_mask, cloth_mask, cloth_mask]) / 255.0\n",
    "    roi = person_image[y1:y2, x1:x2]\n",
    "    \n",
    "    cloth_resized = cv2.resize(cloth_image, (roi.shape[1], roi.shape[0]))\n",
    "    mask_resized = cv2.resize(mask, (roi.shape[1], roi.shape[0]))\n",
    "    \n",
    "    blended_roi = (roi * (1 - mask_resized) + cloth_resized * mask_resized).astype(np.uint8)\n",
    "    \n",
    "    result = person_image.copy()\n",
    "    result[y1:y2, x1:x2] = blended_roi\n",
    "    \n",
    "    return result\n",
    "\n",
    "def main():\n",
    "    person_image_path = \"yg.jpg\"\n",
    "    cloth_image_path = \"cloth_rbg_3.png\"\n",
    "    \n",
    "    result = detect_upper_body(person_image_path)\n",
    "    if result is None:\n",
    "        return\n",
    "    \n",
    "    person_image, upper_body_rect = result\n",
    "    \n",
    "    debug_image = person_image.copy()\n",
    "    cv2.rectangle(debug_image, \n",
    "                 (upper_body_rect[0], upper_body_rect[1]), \n",
    "                 (upper_body_rect[2], upper_body_rect[3]), \n",
    "                 (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Upper Body Detection\", debug_image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    upper_body_width = upper_body_rect[2] - upper_body_rect[0]\n",
    "    upper_body_height = upper_body_rect[3] - upper_body_rect[1]\n",
    "    \n",
    "    print(f\"Upper body dimensions: {upper_body_width}x{upper_body_height}\")\n",
    "    \n",
    "    cloth_result = process_cloth_image(cloth_image_path, upper_body_width, upper_body_height)\n",
    "    if cloth_result is None:\n",
    "        return\n",
    "    \n",
    "    cloth_image, cloth_mask = cloth_result\n",
    "    \n",
    "    cv2.imshow(\"Processed Cloth\", cloth_image)\n",
    "    cv2.imshow(\"Cloth Mask\", cloth_mask)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    result = overlay_cloth(person_image, upper_body_rect, cloth_image, cloth_mask)\n",
    "    \n",
    "    cv2.imshow(\"Original\", person_image)\n",
    "    cv2.imshow(\"Virtual Try-On\", result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    cv2.imwrite(\"virtual_try_on_result.jpg\", result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd26fd0-6345-449a-90d5-9cd858d95139",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cloth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 175\u001b[0m\n\u001b[0;32m    173\u001b[0m     target_width \u001b[38;5;241m=\u001b[39m upper_body_rect[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m upper_body_rect[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    174\u001b[0m     target_height \u001b[38;5;241m=\u001b[39m upper_body_rect[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m upper_body_rect[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 175\u001b[0m     cloth_processed, cloth_mask_processed \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_cloth_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcloth_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_height\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# Overlay cloth\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cloth_processed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[1], line 81\u001b[0m, in \u001b[0;36mprocess_cloth_image\u001b[1;34m(cloth_img, target_width, target_height)\u001b[0m\n\u001b[0;32m     78\u001b[0m MIN_NECK_WIDTH_RATIO \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.4\u001b[39m   \u001b[38;5;66;03m# Minimum neck width ratio (0.3-0.5)\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Load image and create mask\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcloth\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m     82\u001b[0m     cloth_rgb \u001b[38;5;241m=\u001b[39m cloth[:, :, :\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     83\u001b[0m     mask \u001b[38;5;241m=\u001b[39m cloth[:, :, \u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cloth' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Load cloth image (replace with your cloth image path)\n",
    "cloth_image_path = \"cloth_rbg_3.png\"\n",
    "cloth_img = cv2.imread(cloth_image_path, cv2.IMREAD_UNCHANGED)\n",
    "if cloth_img is None:\n",
    "    print(\"Error: Could not read cloth image\")\n",
    "    exit()\n",
    "\n",
    "# Load OpenCV's face and upper body detectors\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "upper_body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_upperbody.xml')\n",
    "\n",
    "def detect_upper_body(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(100, 100))\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        # If no face detected, try detecting upper body directly\n",
    "        upper_bodies = upper_body_cascade.detectMultiScale(\n",
    "            gray, scaleFactor=1.05, minNeighbors=5, minSize=(100, 100))\n",
    "        if len(upper_bodies) == 0:\n",
    "            return None\n",
    "        (x, y, w, h) = upper_bodies[0]\n",
    "        width_expansion = 0.6\n",
    "        upper_body_rect = (\n",
    "            max(0, x - int(w * width_expansion)),\n",
    "            y + int(h * 0.3),\n",
    "            min(frame.shape[1]-1, x + w + int(w * width_expansion)),\n",
    "            y + int(h * 1.2)\n",
    "        )\n",
    "    else:\n",
    "        (x, y, w, h) = faces[0]\n",
    "        upper_bodies = upper_body_cascade.detectMultiScale(\n",
    "            gray[y+h//2:], scaleFactor=1.05, minNeighbors=5, minSize=(w, h))\n",
    "        \n",
    "        if len(upper_bodies) > 0:\n",
    "            (ub_x, ub_y, ub_w, ub_h) = upper_bodies[0]\n",
    "            ub_y += y + h//2\n",
    "            width_expansion = 0.4\n",
    "            upper_body_rect = (\n",
    "                max(0, ub_x - int(ub_w * width_expansion)),\n",
    "                ub_y - int(ub_h * 0.2),\n",
    "                min(frame.shape[1]-1, ub_x + ub_w + int(ub_w * width_expansion)),\n",
    "                ub_y + int(ub_h * 1.1)\n",
    "            )\n",
    "        else:\n",
    "            neck_y = y + h\n",
    "            shoulder_width = int(w * 3.15)\n",
    "            left_shoulder_x = max(0, x - int((shoulder_width - w) / 2))\n",
    "            right_shoulder_x = min(frame.shape[1]-1, left_shoulder_x + shoulder_width)\n",
    "            hips_y = neck_y + int(h * 3)\n",
    "            upper_body_rect = (\n",
    "                left_shoulder_x,\n",
    "                neck_y,\n",
    "                right_shoulder_x,\n",
    "                min(frame.shape[0]-1, hips_y)\n",
    "            )\n",
    "    \n",
    "    if (upper_body_rect[2] <= upper_body_rect[0]) or (upper_body_rect[3] <= upper_body_rect[1]):\n",
    "        return None\n",
    "    \n",
    "    return upper_body_rect\n",
    "\n",
    "def process_cloth_image(cloth_img, target_width, target_height):\n",
    "    if cloth_img.shape[2] == 4:\n",
    "        cloth_rgb = cloth_img[:, :, :3]\n",
    "        mask = cloth_img[:, :, 3]\n",
    "    else:\n",
    "        cloth_rgb = cloth_img.copy()\n",
    "        gray = cv2.cvtColor(cloth_rgb, cv2.COLOR_BGR2GRAY)\n",
    "        _, mask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "        kernel = np.ones((5,5), np.uint8)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    \n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    cloth_cropped = cloth_rgb[y:y+h, x:x+w]\n",
    "    mask_cropped = mask[y:y+h, x:x+w]\n",
    "\n",
    "    max_scale_width = (target_width * 0.95) / w\n",
    "    max_scale_height = (target_height * 0.95) / h\n",
    "    effective_scale = min(max_scale_width, max_scale_height) * 1.2\n",
    "    new_w = int(w * effective_scale)\n",
    "    new_h = int(h * effective_scale)\n",
    "    \n",
    "    cloth_resized = cv2.resize(cloth_cropped, (new_w, new_h))\n",
    "    mask_resized = cv2.resize(mask_cropped, (new_w, new_h))\n",
    "    \n",
    "    cloth_final = np.zeros((target_height, target_width, 3), dtype=np.uint8)\n",
    "    mask_final = np.zeros((target_height, target_width), dtype=np.uint8)\n",
    "    \n",
    "    x_offset = max(0, (target_width - new_w) // 2 + 40)  # Right shift\n",
    "    y_offset = max(0, (target_height - new_h) // 2 - 15)\n",
    "    \n",
    "    y_end = min(y_offset + new_h, target_height)\n",
    "    x_end = min(x_offset + new_w, target_width)\n",
    "    \n",
    "    cloth_final[y_offset:y_end, x_offset:x_end] = cloth_resized[:y_end-y_offset, :x_end-x_offset]\n",
    "    mask_final[y_offset:y_end, x_offset:x_end] = mask_resized[:y_end-y_offset, :x_end-x_offset]\n",
    "    \n",
    "    return cloth_final, mask_final\n",
    "\n",
    "def overlay_cloth(frame, upper_body_rect, cloth_img, cloth_mask):\n",
    "    x1, y1, x2, y2 = upper_body_rect\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    \n",
    "    cloth_resized = cv2.resize(cloth_img, (roi.shape[1], roi.shape[0]))\n",
    "    mask_resized = cv2.resize(cloth_mask, (roi.shape[1], roi.shape[0]))\n",
    "    mask_normalized = cv2.merge([mask_resized, mask_resized, mask_resized]) / 255.0\n",
    "    \n",
    "    blended_roi = (roi * (1 - mask_normalized) + cloth_resized * mask_normalized).astype(np.uint8)\n",
    "    frame[y1:y2, x1:x2] = blended_roi\n",
    "    return frame\n",
    "\n",
    "# Pre-process cloth image once\n",
    "cloth_processed = None\n",
    "cloth_mask_processed = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Flip frame horizontally for mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    # Detect upper body\n",
    "    upper_body_rect = detect_upper_body(frame)\n",
    "    \n",
    "    if upper_body_rect is not None:\n",
    "        # Process cloth image only once\n",
    "        if cloth_processed is None:\n",
    "            target_width = upper_body_rect[2] - upper_body_rect[0]\n",
    "            target_height = upper_body_rect[3] - upper_body_rect[1]\n",
    "            cloth_processed, cloth_mask_processed = process_cloth_image(cloth_img, target_width, target_height)\n",
    "        \n",
    "        # Overlay cloth\n",
    "        if cloth_processed is not None:\n",
    "            frame = overlay_cloth(frame, upper_body_rect, cloth_processed, cloth_mask_processed)\n",
    "    \n",
    "    # Display result\n",
    "    cv2.imshow('Virtual Try-On', frame)\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
